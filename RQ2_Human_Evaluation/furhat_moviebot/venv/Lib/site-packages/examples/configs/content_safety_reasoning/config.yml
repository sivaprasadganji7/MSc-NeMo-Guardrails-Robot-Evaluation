models:
  # Configure your main LLM (OpenAI, NIM, vLLM, etc.)
  - type: main
    engine: openai
    model: gpt-4o-mini

  # Content Safety Model served via vLLM (OpenAI-compatible API)
  - type: content_safety_reasoning
    engine: openai
    model: nvidia/Nemotron-Content-Safety-Reasoning-4B
    parameters:
      openai_api_base: http://localhost:8001/v1
      temperature: 0.6
      top_p: 0.95

rails:
  config:
    content_safety:
      reasoning:
        enabled: false

  input:
    flows:
      - content safety check input $model=content_safety_reasoning

  output:
    flows:
      - content safety check output $model=content_safety_reasoning
