{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GLiNER PII Detection Example\n",
    "\n",
    "This notebook shows how to use GLiNER for PII detection and PII masking in NeMo Guardrails.\n",
    "\n",
    "GLiNER is a Generalist and Lightweight Model for Named Entity Recognition that can detect a wide range of entity types, including comprehensive PII categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have the GLiNER server running:\n",
    "\n",
    "```bash\n",
    "# Install dependencies\n",
    "pip install gliner torch fastapi uvicorn\n",
    "\n",
    "# Start the example server (uses nvidia/gliner-PII model by default)\n",
    "python examples/deployment/gliner_server/gliner_server.py --host 0.0.0.0 --port 1235\n",
    "```\n",
    "\n",
    "For more details, see the [GLiNER server deployment guide](../deployment/gliner_server/README.md).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PII Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nemoguardrails import LLMRails, RailsConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create rails with GLiNER PII detection\n",
    "\n",
    "For this step you'll need your OpenAI API key and the GLiNER server running.\n",
    "\n",
    "For more details on GLiNER integration, check out this [user guide](../../docs/user-guides/community/gliner.md).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure OPENAI_API_KEY is set in your environment\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR OPENAI API KEY\"\n",
    "\n",
    "YAML_CONFIG = \"\"\"\n",
    "models:\n",
    "  - type: main\n",
    "    engine: openai\n",
    "    model: gpt-4o-mini\n",
    "\n",
    "rails:\n",
    "  config:\n",
    "    gliner:\n",
    "      server_endpoint: http://localhost:1235/v1/extract\n",
    "      threshold: 0.5\n",
    "      input:\n",
    "        entities:\n",
    "          - first_name\n",
    "          - last_name\n",
    "          - street_address\n",
    "          - email\n",
    "      output:\n",
    "        entities:\n",
    "          - first_name\n",
    "          - last_name\n",
    "          - street_address\n",
    "          - email\n",
    "  input:\n",
    "    flows:\n",
    "      - gliner detect pii on input\n",
    "\n",
    "  output:\n",
    "    flows:\n",
    "      - gliner detect pii on output\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "config = RailsConfig.from_content(yaml_content=YAML_CONFIG)\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input rails\n",
    "\n",
    "When PII is detected in user input, the request is blocked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rails.generate(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello! I'm John. My email id is text@gmail.com. I live in California, USA.\"}]\n",
    ")\n",
    "\n",
    "info = rails.explain()\n",
    "\n",
    "print(\"Response\")\n",
    "print(\"----------------------------------------\")\n",
    "print(response[\"content\"])\n",
    "\n",
    "\n",
    "print(\"\\n\\nColang history\")\n",
    "print(\"----------------------------------------\")\n",
    "print(info.colang_history)\n",
    "\n",
    "print(\"\\n\\nLLM calls summary\")\n",
    "print(\"----------------------------------------\")\n",
    "info.print_llm_calls_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output rails\n",
    "\n",
    "When PII is detected in the LLM output, the response is blocked.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rails.generate(messages=[{\"role\": \"user\", \"content\": \"give me a sample email id\"}])\n",
    "\n",
    "info = rails.explain()\n",
    "\n",
    "print(\"Response\")\n",
    "print(\"----------------------------------------\\n\\n\")\n",
    "print(response[\"content\"])\n",
    "\n",
    "\n",
    "print(\"\\n\\nColang history\")\n",
    "print(\"----------------------------------------\")\n",
    "print(info.colang_history)\n",
    "\n",
    "print(\"\\n\\nLLM calls summary\")\n",
    "print(\"----------------------------------------\")\n",
    "info.print_llm_calls_summary()\n",
    "\n",
    "\n",
    "print(\"\\n\\nCompletions where PII was detected!\")\n",
    "print(\"----------------------------------------\")\n",
    "print(info.llm_calls[0].completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PII Masking\n",
    "\n",
    "Instead of blocking messages with PII, you can mask the PII before processing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input rails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_CONFIG = \"\"\"\n",
    "models:\n",
    "  - type: main\n",
    "    engine: openai\n",
    "    model: gpt-4o-mini\n",
    "\n",
    "rails:\n",
    "  config:\n",
    "    gliner:\n",
    "      server_endpoint: http://localhost:1235/v1/extract\n",
    "      threshold: 0.5\n",
    "      input:\n",
    "        entities:\n",
    "          - first_name\n",
    "          - city\n",
    "          - country\n",
    "          - email\n",
    "  input:\n",
    "    flows:\n",
    "      - gliner mask pii on input\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "config = RailsConfig.from_content(yaml_content=YAML_CONFIG)\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rails.generate(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello! I'm John. My email id is text@gmail.com. I live in California, USA.\"}]\n",
    ")\n",
    "\n",
    "info = rails.explain()\n",
    "\n",
    "print(\"Response\")\n",
    "print(\"----------------------------------------\")\n",
    "print(response[\"content\"])\n",
    "\n",
    "\n",
    "print(\"\\n\\nColang history\")\n",
    "print(\"----------------------------------------\")\n",
    "print(info.colang_history)\n",
    "\n",
    "print(\"\\n\\nLLM calls summary\")\n",
    "print(\"----------------------------------------\")\n",
    "info.print_llm_calls_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output rails\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YAML_CONFIG = \"\"\"\n",
    "models:\n",
    "  - type: main\n",
    "    engine: openai\n",
    "    model: gpt-4o-mini\n",
    "\n",
    "rails:\n",
    "  config:\n",
    "    gliner:\n",
    "      server_endpoint: http://localhost:1235/v1/extract\n",
    "      threshold: 0.5\n",
    "      output:\n",
    "        entities:\n",
    "          - first_name\n",
    "          - city\n",
    "          - country\n",
    "          - email\n",
    "  output:\n",
    "    flows:\n",
    "      - gliner mask pii on output\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "config = RailsConfig.from_content(yaml_content=YAML_CONFIG)\n",
    "rails = LLMRails(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rails.generate(messages=[{\"role\": \"user\", \"content\": \"give me a sample email id\"}])\n",
    "\n",
    "info = rails.explain()\n",
    "\n",
    "print(\"Response\")\n",
    "print(\"----------------------------------------\\n\\n\")\n",
    "print(response[\"content\"])\n",
    "\n",
    "\n",
    "print(\"\\n\\nColang history\")\n",
    "print(\"----------------------------------------\")\n",
    "print(info.colang_history)\n",
    "\n",
    "print(\"\\n\\nLLM calls summary\")\n",
    "print(\"----------------------------------------\")\n",
    "info.print_llm_calls_summary()\n",
    "\n",
    "\n",
    "print(\"\\n\\nOriginal completion (before masking)\")\n",
    "print(\"----------------------------------------\")\n",
    "print(info.llm_calls[0].completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supported Entity Types\n",
    "\n",
    "The GLiNER server (using the `nvidia/gliner-PII` model) supports these PII categories:\n",
    "\n",
    "| Category | Entity Types |\n",
    "|----------|-------------|\n",
    "| Personal Identifiers | `first_name`, `last_name`, `ssn`, `date_of_birth`, `age`, `gender` |\n",
    "| Contact Information | `email`, `phone_number`, `fax_number`, `street_address`, `city`, `state`, `postcode`, `country`, `county` |\n",
    "| Financial | `credit_debit_card`, `cvv`, `bank_routing_number`, `account_number`, `swift_bic`, `tax_id` |\n",
    "| Technical | `ipv4`, `ipv6`, `mac_address`, `url`, `api_key`, `password`, `pin`, `http_cookie` |\n",
    "| Identification | `national_id`, `license_plate`, `vehicle_identifier`, `employee_id`, `customer_id`, `unique_id` |\n",
    "| Sensitive Attributes | `sexuality`, `political_view`, `race_ethnicity`, `religious_belief`, `blood_type` |\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
